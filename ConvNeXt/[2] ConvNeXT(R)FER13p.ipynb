{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f3a5ab73-07b1-4236-8689-061f8b48c183",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms, datasets\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from timm import create_model\n",
    "import pandas as pd\n",
    "import copy\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a762305b-c77f-4769-9820-7b59aa508a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "train_dataset = datasets.ImageFolder('C:/Users/liamcee/Documents/farbruh/fer13pluh/train', transform=transform)\n",
    "test_dataset = datasets.ImageFolder('C:/Users/liamcee/Documents/farbruh/fer13pluh/test', transform=transform)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=16, shuffle=True, num_workers=4, pin_memory=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=16, shuffle=False, num_workers=4, pin_memory=True)\n",
    "\n",
    "num_classes = len(train_dataset.classes)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "168a320d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\liamcee\\AppData\\Local\\Temp\\ipykernel_45284\\1587508289.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load('ferconvnext_weights.pth'))\n"
     ]
    }
   ],
   "source": [
    "model = create_model('convnext_tiny', pretrained=False, num_classes=num_classes)\n",
    "model.load_state_dict(torch.load('ferconvnext_weights.pth'))\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d44561f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(\"convnext_fer13_metrics.csv\"):\n",
    "    df_metrics = pd.read_csv(\"convnext_fer13_metrics.csv\")\n",
    "    start_epoch = len(df_metrics)\n",
    "    \n",
    "    train_losses = df_metrics['train_loss'].tolist()\n",
    "    train_accuracies = df_metrics['train_accuracy'].tolist()\n",
    "    test_losses = df_metrics['test_loss'].tolist()\n",
    "    test_accuracies = df_metrics['test_accuracy'].tolist()\n",
    "    \n",
    "    best_acc = max(test_accuracies)\n",
    "else:\n",
    "    start_epoch = 0\n",
    "    train_losses, train_accuracies = [], []\n",
    "    test_losses, test_accuracies = [], []\n",
    "    best_acc = 0.0\n",
    "\n",
    "best_model_wts = copy.deepcopy(model.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "21478310",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.AdamW(model.parameters(), lr=3e-5, weight_decay=1e-4)\n",
    "scheduler = StepLR(optimizer, step_size=2, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d0c61905",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses = []\n",
    "train_accuracies = []\n",
    "test_losses = []\n",
    "test_accuracies = []\n",
    "\n",
    "best_acc = 0.0\n",
    "best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "def train(model, loader, optimizer, criterion):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    loop = tqdm(loader, desc=\"Training\")\n",
    "\n",
    "    for images, labels in loop:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "        loop.set_postfix(loss=loss.item(), acc=100.0 * correct / total)\n",
    "\n",
    "    epoch_loss = running_loss / len(loader)\n",
    "    epoch_acc = 100.0 * correct / total\n",
    "    train_losses.append(epoch_loss)\n",
    "    train_accuracies.append(epoch_acc)\n",
    "    print(f\"Train Loss: {epoch_loss:.4f}, Accuracy: {epoch_acc:.2f}%\")\n",
    "\n",
    "def evaluate(model, loader, criterion, epoch):\n",
    "    global best_acc, best_model_wts\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    loop = tqdm(loader, desc=\"Evaluating\")\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in loop:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "            \n",
    "            loop.set_postfix(loss=loss.item(), acc=100.0 * correct / total)\n",
    "\n",
    "    epoch_loss = running_loss / len(loader)\n",
    "    epoch_acc = 100.0 * correct / total\n",
    "    test_losses.append(epoch_loss)\n",
    "    test_accuracies.append(epoch_acc)\n",
    "\n",
    "    print(f\"Test  Loss: {epoch_loss:.4f}, Accuracy: {epoch_acc:.2f}%\")\n",
    "\n",
    "    if epoch_acc > best_acc:\n",
    "        best_acc = epoch_acc\n",
    "        best_model_wts = copy.deepcopy(model.state_dict())\n",
    "        torch.save(best_model_wts, 'best_convnext_fer13p.pth')\n",
    "        print(f\"best model saved with accuracy: {best_acc:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bf83a701",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 21/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1775/1775 [15:49<00:00,  1.87it/s, acc=81.4, loss=0.162] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5341, Accuracy: 81.43%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 444/444 [01:12<00:00,  6.16it/s, acc=83.6, loss=0.487]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test  Loss: 0.4426, Accuracy: 83.60%\n",
      "best model saved with accuracy: 83.60%\n",
      "Epoch Time: 1021.92 seconds\n",
      "\n",
      "Epoch 22/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1775/1775 [15:45<00:00,  1.88it/s, acc=87.1, loss=0.0177]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3430, Accuracy: 87.06%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 444/444 [01:10<00:00,  6.29it/s, acc=83, loss=0.618]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test  Loss: 0.4565, Accuracy: 82.98%\n",
      "Epoch Time: 1016.10 seconds\n",
      "\n",
      "Epoch 23/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1775/1775 [15:48<00:00,  1.87it/s, acc=94, loss=0.0218]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1774, Accuracy: 94.01%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 444/444 [01:09<00:00,  6.36it/s, acc=85, loss=0.722]     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test  Loss: 0.4804, Accuracy: 84.96%\n",
      "best model saved with accuracy: 84.96%\n",
      "Epoch Time: 1018.43 seconds\n",
      "\n",
      "Epoch 24/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1775/1775 [15:23<00:00,  1.92it/s, acc=95.7, loss=4.7e-5] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1319, Accuracy: 95.69%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 444/444 [00:55<00:00,  7.98it/s, acc=84.7, loss=0.844]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test  Loss: 0.5447, Accuracy: 84.66%\n",
      "Epoch Time: 979.49 seconds\n",
      "\n",
      "Epoch 25/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1775/1775 [15:39<00:00,  1.89it/s, acc=97.1, loss=0.000974]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0956, Accuracy: 97.12%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 444/444 [01:09<00:00,  6.43it/s, acc=84.8, loss=0.905]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test  Loss: 0.5688, Accuracy: 84.84%\n",
      "Epoch Time: 1008.83 seconds\n",
      "\n",
      "Epoch 26/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1775/1775 [15:47<00:00,  1.87it/s, acc=97.3, loss=0.00143]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0899, Accuracy: 97.31%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 444/444 [01:09<00:00,  6.41it/s, acc=84.8, loss=0.944]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test  Loss: 0.5963, Accuracy: 84.76%\n",
      "Epoch Time: 1016.97 seconds\n",
      "\n",
      "Epoch 27/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1775/1775 [15:47<00:00,  1.87it/s, acc=97.4, loss=0.00272] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0854, Accuracy: 97.44%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 444/444 [01:10<00:00,  6.30it/s, acc=84.7, loss=0.947]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test  Loss: 0.5993, Accuracy: 84.70%\n",
      "Epoch Time: 1018.10 seconds\n",
      "\n",
      "Epoch 28/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1775/1775 [15:44<00:00,  1.88it/s, acc=97.5, loss=0.00168] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0849, Accuracy: 97.45%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 444/444 [01:10<00:00,  6.27it/s, acc=84.7, loss=0.95]    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test  Loss: 0.6022, Accuracy: 84.69%\n",
      "Epoch Time: 1014.98 seconds\n",
      "\n",
      "Epoch 29/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1775/1775 [07:27<00:00,  3.96it/s, acc=97.5, loss=0.0331] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0845, Accuracy: 97.48%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 444/444 [00:33<00:00, 13.23it/s, acc=84.7, loss=0.95]    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test  Loss: 0.6024, Accuracy: 84.69%\n",
      "Epoch Time: 481.45 seconds\n",
      "\n",
      "Epoch 30/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1775/1775 [06:50<00:00,  4.33it/s, acc=97.5, loss=5.07e-6]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0844, Accuracy: 97.49%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 444/444 [00:33<00:00, 13.27it/s, acc=84.7, loss=0.95]    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test  Loss: 0.6025, Accuracy: 84.69%\n",
      "Epoch Time: 443.59 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "for epoch in range(start_epoch, start_epoch + epochs):\n",
    "    print(f\"\\nEpoch {epoch+1}/{start_epoch + epochs}\")\n",
    "    start_time = time.time()\n",
    "\n",
    "    train(model, train_loader, optimizer, criterion)\n",
    "    evaluate(model, test_loader, criterion, epoch)\n",
    "\n",
    "    scheduler.step()\n",
    "\n",
    "    elapsed = time.time() - start_time\n",
    "    print(f\"Epoch Time: {elapsed:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6c6d2274",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = {\n",
    "    'epoch': list(range(1, len(train_losses) + 1)),\n",
    "    'train_loss': train_losses,\n",
    "    'train_accuracy': train_accuracies,\n",
    "    'test_loss': test_losses,\n",
    "    'test_accuracy': test_accuracies\n",
    "}\n",
    "\n",
    "df_metrics = pd.DataFrame(metrics)\n",
    "df_metrics.to_csv(\"convnext_fer13_metrics(R).csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b61d8dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'ferconvnext_weights(R).pth')\n",
    "torch.save(model, 'ferconvnext_full(R).pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "farfromhome",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
