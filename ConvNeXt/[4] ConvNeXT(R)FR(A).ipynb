{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f3a5ab73-07b1-4236-8689-061f8b48c183",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms, datasets\n",
    "from torchvision.transforms import v2\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from timm import create_model\n",
    "import pandas as pd\n",
    "import copy\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a762305b-c77f-4769-9820-7b59aa508a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = v2.Compose([\n",
    "    v2.ToImage(),\n",
    "    v2.ToDtype(torch.float32, scale=True),\n",
    "    v2.RandomResizedCrop(224, scale=(0.8, 1.0)),\n",
    "    v2.RandomHorizontalFlip(p=0.5),\n",
    "    v2.ColorJitter(0.2, 0.2, 0.2, 0.1),\n",
    "    v2.RandomRotation(15),\n",
    "    v2.RandomErasing(p=0.3),\n",
    "    v2.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                 std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "val_transform = v2.Compose([\n",
    "    v2.ToImage(),\n",
    "    v2.Resize((224, 224)),\n",
    "    v2.ToDtype(torch.float32, scale=True),\n",
    "    v2.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                 std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "train_dataset = datasets.ImageFolder('C:/Users/liamcee/Documents/farbruh/rafdb/train', transform=train_transform)\n",
    "test_dataset = datasets.ImageFolder('C:/Users/liamcee/Documents/farbruh/rafdb/test', transform=val_transform)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=16, shuffle=True, num_workers=4, pin_memory=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=16, shuffle=False, num_workers=4, pin_memory=True)\n",
    "\n",
    "num_classes = len(train_dataset.classes)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "168a320d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\liamcee\\AppData\\Local\\Temp\\ipykernel_19540\\2301285810.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load('FRconvnext_weights(R)(A).pth'))\n"
     ]
    }
   ],
   "source": [
    "model = create_model('convnext_tiny', pretrained=False, num_classes=num_classes)\n",
    "model.load_state_dict(torch.load('FRconvnext_weights(R)(A).pth'))\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d44561f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(\"convnext_FpR_metrics(R)(A).csv\"):\n",
    "    df_metrics = pd.read_csv(\"convnext_FpR_metrics(R)(A).csv\")\n",
    "    start_epoch = len(df_metrics)\n",
    "    \n",
    "    train_losses = df_metrics['train_loss'].tolist()\n",
    "    train_accuracies = df_metrics['train_accuracy'].tolist()\n",
    "    test_losses = df_metrics['test_loss'].tolist()\n",
    "    test_accuracies = df_metrics['test_accuracy'].tolist()\n",
    "    \n",
    "    best_acc = max(test_accuracies)\n",
    "else:\n",
    "    start_epoch = 0\n",
    "    train_losses, train_accuracies = [], []\n",
    "    test_losses, test_accuracies = [], []\n",
    "    best_acc = 0.0\n",
    "\n",
    "best_model_wts = copy.deepcopy(model.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "21478310",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.AdamW(model.parameters(), lr=3e-5, weight_decay=1e-4)\n",
    "scheduler = StepLR(optimizer, step_size=2, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d0c61905",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses = []\n",
    "train_accuracies = []\n",
    "test_losses = []\n",
    "test_accuracies = []\n",
    "\n",
    "best_acc = 0.0\n",
    "best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "def train(model, loader, optimizer, criterion):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    loop = tqdm(loader, desc=\"Training\")\n",
    "\n",
    "    for images, labels in loop:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "        loop.set_postfix(loss=loss.item(), acc=100.0 * correct / total)\n",
    "\n",
    "    epoch_loss = running_loss / len(loader)\n",
    "    epoch_acc = 100.0 * correct / total\n",
    "    train_losses.append(epoch_loss)\n",
    "    train_accuracies.append(epoch_acc)\n",
    "    print(f\"Train Loss: {epoch_loss:.4f}, Accuracy: {epoch_acc:.2f}%\")\n",
    "\n",
    "def evaluate(model, loader, criterion, epoch):\n",
    "    global best_acc, best_model_wts\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    loop = tqdm(loader, desc=\"Evaluating\")\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in loop:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "            \n",
    "            loop.set_postfix(loss=loss.item(), acc=100.0 * correct / total)\n",
    "\n",
    "    epoch_loss = running_loss / len(loader)\n",
    "    epoch_acc = 100.0 * correct / total\n",
    "    test_losses.append(epoch_loss)\n",
    "    test_accuracies.append(epoch_acc)\n",
    "\n",
    "    print(f\"Test  Loss: {epoch_loss:.4f}, Accuracy: {epoch_acc:.2f}%\")\n",
    "\n",
    "    if epoch_acc > best_acc:\n",
    "        best_acc = epoch_acc\n",
    "        best_model_wts = copy.deepcopy(model.state_dict())\n",
    "        torch.save(best_model_wts, 'best_convnext_FR(A).pth')\n",
    "        print(f\"best model saved with accuracy: {best_acc:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bf83a701",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 11/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 767/767 [06:33<00:00,  1.95it/s, acc=82.7, loss=0.656] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.4889, Accuracy: 82.67%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 192/192 [00:44<00:00,  4.32it/s, acc=85.8, loss=0.615] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test  Loss: 0.4084, Accuracy: 85.82%\n",
      "best model saved with accuracy: 85.82%\n",
      "Epoch Time: 438.06 seconds\n",
      "\n",
      "Epoch 12/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 767/767 [06:27<00:00,  1.98it/s, acc=86.5, loss=0.183] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3799, Accuracy: 86.47%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 192/192 [00:40<00:00,  4.75it/s, acc=86.1, loss=0.747] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test  Loss: 0.3998, Accuracy: 86.11%\n",
      "best model saved with accuracy: 86.11%\n",
      "Epoch Time: 427.81 seconds\n",
      "\n",
      "Epoch 13/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 767/767 [06:37<00:00,  1.93it/s, acc=90.3, loss=0.375] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2776, Accuracy: 90.26%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 192/192 [00:31<00:00,  6.04it/s, acc=87.1, loss=0.633]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test  Loss: 0.3846, Accuracy: 87.13%\n",
      "best model saved with accuracy: 87.13%\n",
      "Epoch Time: 429.26 seconds\n",
      "\n",
      "Epoch 14/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 767/767 [06:39<00:00,  1.92it/s, acc=91.1, loss=0.293] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2556, Accuracy: 91.15%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 192/192 [00:33<00:00,  5.70it/s, acc=87.7, loss=0.667]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test  Loss: 0.3871, Accuracy: 87.68%\n",
      "best model saved with accuracy: 87.68%\n",
      "Epoch Time: 433.69 seconds\n",
      "\n",
      "Epoch 15/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 767/767 [06:28<00:00,  1.97it/s, acc=91.7, loss=0.285]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2416, Accuracy: 91.69%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 192/192 [00:43<00:00,  4.41it/s, acc=87.5, loss=0.63]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test  Loss: 0.3886, Accuracy: 87.55%\n",
      "Epoch Time: 432.35 seconds\n",
      "\n",
      "Epoch 16/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 767/767 [06:29<00:00,  1.97it/s, acc=91.5, loss=0.186] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2433, Accuracy: 91.49%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 192/192 [00:45<00:00,  4.23it/s, acc=87.4, loss=0.61]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test  Loss: 0.3914, Accuracy: 87.42%\n",
      "Epoch Time: 435.15 seconds\n",
      "\n",
      "Epoch 17/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 767/767 [06:29<00:00,  1.97it/s, acc=91.7, loss=0.0348] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2416, Accuracy: 91.66%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 192/192 [00:43<00:00,  4.39it/s, acc=87.5, loss=0.603]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test  Loss: 0.3911, Accuracy: 87.45%\n",
      "Epoch Time: 432.91 seconds\n",
      "\n",
      "Epoch 18/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 767/767 [06:43<00:00,  1.90it/s, acc=91.6, loss=0.108] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2423, Accuracy: 91.65%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 192/192 [00:33<00:00,  5.79it/s, acc=87.5, loss=0.605]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test  Loss: 0.3908, Accuracy: 87.45%\n",
      "Epoch Time: 436.29 seconds\n",
      "\n",
      "Epoch 19/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 767/767 [03:03<00:00,  4.18it/s, acc=91.4, loss=0.229] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2398, Accuracy: 91.42%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 192/192 [00:20<00:00,  9.23it/s, acc=87.5, loss=0.604]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test  Loss: 0.3908, Accuracy: 87.45%\n",
      "Epoch Time: 204.26 seconds\n",
      "\n",
      "Epoch 20/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 767/767 [03:03<00:00,  4.17it/s, acc=91.7, loss=0.0414]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2414, Accuracy: 91.70%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 192/192 [00:20<00:00,  9.29it/s, acc=87.5, loss=0.604]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test  Loss: 0.3907, Accuracy: 87.45%\n",
      "Epoch Time: 204.46 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "for epoch in range(start_epoch, start_epoch + epochs):\n",
    "    print(f\"\\nEpoch {epoch+1}/{start_epoch + epochs}\")\n",
    "    start_time = time.time()\n",
    "\n",
    "    train(model, train_loader, optimizer, criterion)\n",
    "    evaluate(model, test_loader, criterion, epoch)\n",
    "\n",
    "    scheduler.step()\n",
    "\n",
    "    elapsed = time.time() - start_time\n",
    "    print(f\"Epoch Time: {elapsed:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6c6d2274",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = {\n",
    "    'epoch': list(range(1, len(train_losses) + 1)),\n",
    "    'train_loss': train_losses,\n",
    "    'train_accuracy': train_accuracies,\n",
    "    'test_loss': test_losses,\n",
    "    'test_accuracy': test_accuracies\n",
    "}\n",
    "\n",
    "df_metrics = pd.DataFrame(metrics)\n",
    "df_metrics.to_csv(\"convnext_FpRa_metrics(R)(A).csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b61d8dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'FRconvnext_weights(R)(A).pth')\n",
    "torch.save(model, 'FRconvnext_full(R)(A).pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "farfromhome",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
