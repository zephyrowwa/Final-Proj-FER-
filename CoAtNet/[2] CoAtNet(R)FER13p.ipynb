{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a77840a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms, datasets\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from timm import create_model\n",
    "import pandas as pd\n",
    "import copy\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "60b459c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5]*3, [0.5]*3)\n",
    "])\n",
    "\n",
    "train_dataset = datasets.ImageFolder('C:/Users/liamcee/Documents/farbruh/fer13pluh/train', transform=transform)\n",
    "test_dataset = datasets.ImageFolder('C:/Users/liamcee/Documents/farbruh/fer13pluh/test', transform=transform)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=16, shuffle=True, num_workers=4, pin_memory=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=16, shuffle=False, num_workers=4, pin_memory=True)\n",
    "\n",
    "num_classes = len(train_dataset.classes)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e56a03a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\liamcee\\AppData\\Local\\Temp\\ipykernel_20168\\3599719758.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load('fercoatnet_weights.pth'))\n"
     ]
    }
   ],
   "source": [
    "model = create_model('coatnet_0_rw_224.sw_in1k', pretrained=False, num_classes=num_classes)\n",
    "model.load_state_dict(torch.load('fercoatnet_weights.pth'))\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bcb95c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(\"coatnet_fer13_metrics.csv\"):\n",
    "    df_metrics = pd.read_csv(\"coatnet_fer13_metrics.csv\")\n",
    "    start_epoch = len(df_metrics)\n",
    "    \n",
    "    train_losses = df_metrics['train_loss'].tolist()\n",
    "    train_accuracies = df_metrics['train_accuracy'].tolist()\n",
    "    test_losses = df_metrics['test_loss'].tolist()\n",
    "    test_accuracies = df_metrics['test_accuracy'].tolist()\n",
    "    \n",
    "    best_acc = max(test_accuracies)\n",
    "else:\n",
    "    start_epoch = 0\n",
    "    train_losses, train_accuracies = [], []\n",
    "    test_losses, test_accuracies = [], []\n",
    "    best_acc = 0.0\n",
    "\n",
    "best_model_wts = copy.deepcopy(model.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ac7d2b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.AdamW(model.parameters(), lr=3e-5, weight_decay=1e-4)\n",
    "scheduler = StepLR(optimizer, step_size=2, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "821bcf81",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses = []\n",
    "train_accuracies = []\n",
    "test_losses = []\n",
    "test_accuracies = []\n",
    "\n",
    "best_acc = 0.0\n",
    "best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "def train(model, loader, optimizer, criterion):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    loop = tqdm(loader, desc=\"Training\")\n",
    "\n",
    "    for images, labels in loop:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "        loop.set_postfix(loss=loss.item(), acc=100.0 * correct / total)\n",
    "\n",
    "    epoch_loss = running_loss / len(loader)\n",
    "    epoch_acc = 100.0 * correct / total\n",
    "    train_losses.append(epoch_loss)\n",
    "    train_accuracies.append(epoch_acc)\n",
    "    print(f\"Train Loss: {epoch_loss:.4f}, Accuracy: {epoch_acc:.2f}%\")\n",
    "\n",
    "def evaluate(model, loader, criterion, epoch):\n",
    "    global best_acc, best_model_wts\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    loop = tqdm(loader, desc=\"Evaluating\")\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in loop:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "            \n",
    "            loop.set_postfix(loss=loss.item(), acc=100.0 * correct / total)\n",
    "\n",
    "    epoch_loss = running_loss / len(loader)\n",
    "    epoch_acc = 100.0 * correct / total\n",
    "    test_losses.append(epoch_loss)\n",
    "    test_accuracies.append(epoch_acc)\n",
    "\n",
    "    print(f\"Test  Loss: {epoch_loss:.4f}, Accuracy: {epoch_acc:.2f}%\")\n",
    "\n",
    "    # Save best model\n",
    "    if epoch_acc > best_acc:\n",
    "        best_acc = epoch_acc\n",
    "        best_model_wts = copy.deepcopy(model.state_dict())\n",
    "        torch.save(best_model_wts, 'best_coatnet_fer13p.pth')\n",
    "        print(f\"best model saved with accuracy: {best_acc:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6698b74b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 21/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1775/1775 [05:33<00:00,  5.32it/s, acc=81.7, loss=0.055] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5304, Accuracy: 81.70%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 444/444 [00:35<00:00, 12.67it/s, acc=82.1, loss=0.752]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test  Loss: 0.4804, Accuracy: 82.08%\n",
      "best model saved with accuracy: 82.08%\n",
      "Epoch Time: 368.91 seconds\n",
      "\n",
      "Epoch 22/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1775/1775 [05:31<00:00,  5.35it/s, acc=87.1, loss=1.19]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3477, Accuracy: 87.07%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 444/444 [00:36<00:00, 12.08it/s, acc=84, loss=0.552]    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test  Loss: 0.4413, Accuracy: 84.03%\n",
      "best model saved with accuracy: 84.03%\n",
      "Epoch Time: 368.56 seconds\n",
      "\n",
      "Epoch 23/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1775/1775 [05:44<00:00,  5.16it/s, acc=93.2, loss=1.38]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1938, Accuracy: 93.20%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 444/444 [00:36<00:00, 12.24it/s, acc=84.3, loss=0.453]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test  Loss: 0.4831, Accuracy: 84.28%\n",
      "best model saved with accuracy: 84.28%\n",
      "Epoch Time: 380.48 seconds\n",
      "\n",
      "Epoch 24/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1775/1775 [05:44<00:00,  5.15it/s, acc=94.9, loss=0.00035]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1476, Accuracy: 94.88%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 444/444 [00:37<00:00, 11.87it/s, acc=84.1, loss=0.629]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test  Loss: 0.5406, Accuracy: 84.05%\n",
      "Epoch Time: 382.34 seconds\n",
      "\n",
      "Epoch 25/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1775/1775 [05:37<00:00,  5.26it/s, acc=96.3, loss=0.0124] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1118, Accuracy: 96.35%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 444/444 [00:35<00:00, 12.57it/s, acc=84.3, loss=0.513]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test  Loss: 0.5547, Accuracy: 84.25%\n",
      "Epoch Time: 372.57 seconds\n",
      "\n",
      "Epoch 26/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1775/1775 [05:32<00:00,  5.34it/s, acc=96.5, loss=0.0609] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1058, Accuracy: 96.48%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 444/444 [00:35<00:00, 12.61it/s, acc=84.2, loss=0.474]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test  Loss: 0.5726, Accuracy: 84.21%\n",
      "Epoch Time: 367.36 seconds\n",
      "\n",
      "Epoch 27/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1775/1775 [05:34<00:00,  5.31it/s, acc=96.6, loss=0.000382]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1031, Accuracy: 96.55%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 444/444 [00:35<00:00, 12.44it/s, acc=84.3, loss=0.478]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test  Loss: 0.5725, Accuracy: 84.28%\n",
      "Epoch Time: 369.82 seconds\n",
      "\n",
      "Epoch 28/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1775/1775 [05:34<00:00,  5.30it/s, acc=96.6, loss=0.296]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1032, Accuracy: 96.59%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 444/444 [00:34<00:00, 12.76it/s, acc=84.3, loss=0.463]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test  Loss: 0.5743, Accuracy: 84.31%\n",
      "best model saved with accuracy: 84.31%\n",
      "Epoch Time: 369.82 seconds\n",
      "\n",
      "Epoch 29/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1775/1775 [05:32<00:00,  5.33it/s, acc=96.6, loss=3.4e-5] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1025, Accuracy: 96.62%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 444/444 [00:36<00:00, 12.06it/s, acc=84.4, loss=0.461]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test  Loss: 0.5751, Accuracy: 84.41%\n",
      "best model saved with accuracy: 84.41%\n",
      "Epoch Time: 369.89 seconds\n",
      "\n",
      "Epoch 30/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1775/1775 [05:34<00:00,  5.30it/s, acc=96.6, loss=4.73e-5] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1028, Accuracy: 96.62%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 444/444 [00:35<00:00, 12.56it/s, acc=84.3, loss=0.478]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test  Loss: 0.5737, Accuracy: 84.29%\n",
      "Epoch Time: 369.99 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "for epoch in range(start_epoch, start_epoch + epochs):\n",
    "    print(f\"\\nEpoch {epoch+1}/{start_epoch + epochs}\")\n",
    "    start_time = time.time()\n",
    "\n",
    "    train(model, train_loader, optimizer, criterion)\n",
    "    evaluate(model, test_loader, criterion, epoch)\n",
    "\n",
    "    scheduler.step()\n",
    "    \n",
    "    elapsed = time.time() - start_time\n",
    "    print(f\"Epoch Time: {elapsed:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "527641cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = {\n",
    "    'epoch': list(range(1, len(train_losses) + 1)),\n",
    "    'train_loss': train_losses,\n",
    "    'train_accuracy': train_accuracies,\n",
    "    'test_loss': test_losses,\n",
    "    'test_accuracy': test_accuracies\n",
    "}\n",
    "\n",
    "df_metrics = pd.DataFrame(metrics)\n",
    "df_metrics.to_csv(\"coatnet_fer13_metrics(R).csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f83ee9ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'fercoatnet_weights(R).pth')\n",
    "torch.save(model, 'fercoatnet_full(R).pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a672992a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "farfromhome",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
