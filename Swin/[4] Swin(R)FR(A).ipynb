{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f3a5ab73-07b1-4236-8689-061f8b48c183",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms, datasets\n",
    "from torchvision.transforms import v2\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from timm import create_model\n",
    "import pandas as pd\n",
    "import copy\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a762305b-c77f-4769-9820-7b59aa508a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = v2.Compose([\n",
    "    v2.ToImage(),\n",
    "    v2.ToDtype(torch.float32, scale=True),\n",
    "    v2.RandomResizedCrop(224, scale=(0.8, 1.0)),\n",
    "    v2.RandomHorizontalFlip(p=0.5),\n",
    "    v2.ColorJitter(0.2, 0.2, 0.2, 0.1),\n",
    "    v2.RandomRotation(15),\n",
    "    v2.RandomErasing(p=0.3),\n",
    "    v2.Normalize([0.5]*3, [0.5]*3)\n",
    "])\n",
    "\n",
    "val_transform = v2.Compose([\n",
    "    v2.ToImage(),\n",
    "    v2.Resize((224, 224)),\n",
    "    v2.ToDtype(torch.float32, scale=True),\n",
    "    v2.Normalize([0.5]*3, [0.5]*3)\n",
    "])\n",
    "\n",
    "train_dataset = datasets.ImageFolder('C:/Users/liamcee/Documents/farbruh/rafdb/train', transform=train_transform)\n",
    "test_dataset = datasets.ImageFolder('C:/Users/liamcee/Documents/farbruh/rafdb/test', transform=val_transform)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=16, shuffle=True, num_workers=4, pin_memory=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=16, shuffle=False, num_workers=4, pin_memory=True)\n",
    "\n",
    "num_classes = len(train_dataset.classes)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "168a320d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\liamcee\\AppData\\Local\\Temp\\ipykernel_18308\\2096223671.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load('FRswin_weights(R)(A).pth'))\n"
     ]
    }
   ],
   "source": [
    "model = create_model('swin_tiny_patch4_window7_224', pretrained=False, num_classes=num_classes)\n",
    "model.load_state_dict(torch.load('FRswin_weights(R)(A).pth'))\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d44561f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(\"swin_FpR_metrics(R)(A).csv\"):\n",
    "    df_metrics = pd.read_csv(\"swin_FpR_metrics(R)(A).csv\")\n",
    "    start_epoch = len(df_metrics)\n",
    "    \n",
    "    train_losses = df_metrics['train_loss'].tolist()\n",
    "    train_accuracies = df_metrics['train_accuracy'].tolist()\n",
    "    test_losses = df_metrics['test_loss'].tolist()\n",
    "    test_accuracies = df_metrics['test_accuracy'].tolist()\n",
    "    \n",
    "    best_acc = max(test_accuracies)\n",
    "else:\n",
    "    start_epoch = 0\n",
    "    train_losses, train_accuracies = [], []\n",
    "    test_losses, test_accuracies = [], []\n",
    "    best_acc = 0.0\n",
    "\n",
    "best_model_wts = copy.deepcopy(model.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "21478310",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.AdamW(model.parameters(), lr=3e-5, weight_decay=1e-4)\n",
    "scheduler = StepLR(optimizer, step_size=2, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d0c61905",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses = []\n",
    "train_accuracies = []\n",
    "test_losses = []\n",
    "test_accuracies = []\n",
    "\n",
    "best_acc = 0.0\n",
    "best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "def train(model, loader, optimizer, criterion):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    loop = tqdm(loader, desc=\"Training\")\n",
    "\n",
    "    for images, labels in loop:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "        loop.set_postfix(loss=loss.item(), acc=100.0 * correct / total)\n",
    "\n",
    "    epoch_loss = running_loss / len(loader)\n",
    "    epoch_acc = 100.0 * correct / total\n",
    "    train_losses.append(epoch_loss)\n",
    "    train_accuracies.append(epoch_acc)\n",
    "    print(f\"Train Loss: {epoch_loss:.4f}, Accuracy: {epoch_acc:.2f}%\")\n",
    "\n",
    "def evaluate(model, loader, criterion, epoch):\n",
    "    global best_acc, best_model_wts\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    loop = tqdm(loader, desc=\"Evaluating\")\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in loop:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "            \n",
    "            loop.set_postfix(loss=loss.item(), acc=100.0 * correct / total)\n",
    "\n",
    "    epoch_loss = running_loss / len(loader)\n",
    "    epoch_acc = 100.0 * correct / total\n",
    "    test_losses.append(epoch_loss)\n",
    "    test_accuracies.append(epoch_acc)\n",
    "\n",
    "    print(f\"Test  Loss: {epoch_loss:.4f}, Accuracy: {epoch_acc:.2f}%\")\n",
    "\n",
    "    if epoch_acc > best_acc:\n",
    "        best_acc = epoch_acc\n",
    "        best_model_wts = copy.deepcopy(model.state_dict())\n",
    "        torch.save(best_model_wts, 'best_swin_FR(A).pth')\n",
    "        print(f\"best model saved with accuracy: {best_acc:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bf83a701",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 11/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 767/767 [03:46<00:00,  3.39it/s, acc=79.9, loss=0.433] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5704, Accuracy: 79.92%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 192/192 [00:48<00:00,  3.99it/s, acc=82.6, loss=0.824] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test  Loss: 0.4804, Accuracy: 82.59%\n",
      "best model saved with accuracy: 82.59%\n",
      "Epoch Time: 274.61 seconds\n",
      "\n",
      "Epoch 12/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 767/767 [04:47<00:00,  2.67it/s, acc=82.5, loss=0.192] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.4911, Accuracy: 82.47%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 192/192 [00:47<00:00,  4.02it/s, acc=85, loss=0.796]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test  Loss: 0.4249, Accuracy: 85.04%\n",
      "best model saved with accuracy: 85.04%\n",
      "Epoch Time: 335.02 seconds\n",
      "\n",
      "Epoch 13/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 767/767 [05:23<00:00,  2.37it/s, acc=85.5, loss=0.564] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.4123, Accuracy: 85.49%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 192/192 [00:36<00:00,  5.22it/s, acc=87, loss=0.485]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test  Loss: 0.3860, Accuracy: 86.96%\n",
      "best model saved with accuracy: 86.96%\n",
      "Epoch Time: 360.39 seconds\n",
      "\n",
      "Epoch 14/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 767/767 [05:56<00:00,  2.15it/s, acc=85.7, loss=0.467] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.4031, Accuracy: 85.67%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 192/192 [00:37<00:00,  5.19it/s, acc=87.1, loss=0.411] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test  Loss: 0.3888, Accuracy: 87.06%\n",
      "best model saved with accuracy: 87.06%\n",
      "Epoch Time: 393.60 seconds\n",
      "\n",
      "Epoch 15/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 767/767 [05:48<00:00,  2.20it/s, acc=86.2, loss=0.522] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3883, Accuracy: 86.16%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 192/192 [00:46<00:00,  4.12it/s, acc=87, loss=0.428]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test  Loss: 0.3856, Accuracy: 86.99%\n",
      "Epoch Time: 394.71 seconds\n",
      "\n",
      "Epoch 16/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 767/767 [05:10<00:00,  2.47it/s, acc=86.8, loss=0.242] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3853, Accuracy: 86.77%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 192/192 [00:48<00:00,  3.98it/s, acc=86.9, loss=0.437] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test  Loss: 0.3844, Accuracy: 86.86%\n",
      "Epoch Time: 358.94 seconds\n",
      "\n",
      "Epoch 17/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 767/767 [04:49<00:00,  2.65it/s, acc=86.4, loss=0.351] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3858, Accuracy: 86.44%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 192/192 [00:47<00:00,  4.07it/s, acc=86.9, loss=0.436] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test  Loss: 0.3841, Accuracy: 86.86%\n",
      "Epoch Time: 337.20 seconds\n",
      "\n",
      "Epoch 18/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 767/767 [04:45<00:00,  2.68it/s, acc=85.8, loss=0.568] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3950, Accuracy: 85.84%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 192/192 [00:46<00:00,  4.11it/s, acc=86.9, loss=0.438] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test  Loss: 0.3841, Accuracy: 86.90%\n",
      "Epoch Time: 332.62 seconds\n",
      "\n",
      "Epoch 19/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 767/767 [05:16<00:00,  2.42it/s, acc=86.2, loss=0.355] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3905, Accuracy: 86.18%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 192/192 [00:39<00:00,  4.91it/s, acc=86.9, loss=0.438] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test  Loss: 0.3841, Accuracy: 86.90%\n",
      "Epoch Time: 355.52 seconds\n",
      "\n",
      "Epoch 20/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 767/767 [05:56<00:00,  2.15it/s, acc=86, loss=0.274]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3872, Accuracy: 85.98%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 192/192 [00:36<00:00,  5.30it/s, acc=86.9, loss=0.438] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test  Loss: 0.3841, Accuracy: 86.90%\n",
      "Epoch Time: 393.22 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "for epoch in range(start_epoch, start_epoch + epochs):\n",
    "    print(f\"\\nEpoch {epoch+1}/{start_epoch + epochs}\")\n",
    "    start_time = time.time()\n",
    "\n",
    "    train(model, train_loader, optimizer, criterion)\n",
    "    evaluate(model, test_loader, criterion, epoch)\n",
    "\n",
    "    scheduler.step()\n",
    "\n",
    "    elapsed = time.time() - start_time\n",
    "    print(f\"Epoch Time: {elapsed:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6c6d2274",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = {\n",
    "    'epoch': list(range(1, len(train_losses) + 1)),\n",
    "    'train_loss': train_losses,\n",
    "    'train_accuracy': train_accuracies,\n",
    "    'test_loss': test_losses,\n",
    "    'test_accuracy': test_accuracies\n",
    "}\n",
    "\n",
    "df_metrics = pd.DataFrame(metrics)\n",
    "df_metrics.to_csv(\"swin_FpRa_metrics(R)(A).csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b61d8dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'FRswin_weights(R)(A).pth')\n",
    "torch.save(model, 'FRswin_full(R)(A).pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "farfromhome",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
